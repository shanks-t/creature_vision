{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET = \"ml_challenger_state\"\n",
    "GCS_STATE_FILE = \"model_versions.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_versions():\n",
    "    client = storage.Client()\n",
    "    blob = client.bucket(GCS_BUCKET).blob(GCS_STATE_FILE)\n",
    "    data = json.loads(blob.download_as_text())\n",
    "    return data, blob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"creature-vision\"\n",
    "BQ_METRICS_TABLE = \"creature-vision.dog_prediction_app.prediction_metrics\"\n",
    "def evaluate_models(champion_version: str, challenger_version: str) -> str:\n",
    "    bq = bigquery.Client(project=PROJECT_ID)\n",
    "    query = f\"\"\"\n",
    "        SELECT model_version, AVG(CAST(is_correct AS INT64)) AS avg_prediction_accuracy\n",
    "        FROM `{BQ_METRICS_TABLE}`\n",
    "        WHERE model_version IN ('{champion_version}', '{challenger_version}')\n",
    "        GROUP BY model_version\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        row.model_version: row.avg_prediction_accuracy\n",
    "        for row in bq.query(query).result()\n",
    "    }\n",
    "    print(\"Model accuracies:\", results)\n",
    "\n",
    "    champ_score = results.get(champion_version, 0.0)\n",
    "    chall_score = results.get(challenger_version, 0.0)\n",
    "\n",
    "    return challenger_version if chall_score > champ_score else champion_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_versions(blob, data, winner: str, model_version: str):\n",
    "    if data[\"champion\"][\"model_version\"] != winner:\n",
    "        print(f\"Promoting {winner} to champion\")\n",
    "        data[\"champion\"] = {\n",
    "            \"model_version\": winner,\n",
    "            \"deployed_at\": datetime.datetime.now().isoformat() + \"Z\",\n",
    "        }\n",
    "        \n",
    "        current_version = data['challenger']['model_version']\n",
    "        version_parts = current_version.strip('v').split('_')\n",
    "        major, minor = map(int, version_parts)\n",
    "\n",
    "        new_challenger_version = f\"v{major}_{minor + 1}\"\n",
    "        print(f\"New challenger: {new_challenger_version}\")\n",
    "        data[\"challenger\"] = {\n",
    "            \"model_version\": new_challenger_version,\n",
    "            \"deployed_at\": None,\n",
    "        }\n",
    "        blob.upload_from_string(json.dumps(data, indent=2))\n",
    "        return winner, \"champion-service\", new_challenger_version\n",
    "    else:\n",
    "        current_version = data['challenger']['model_version']\n",
    "        version_parts = current_version.strip('v').split('_')\n",
    "        major, minor = map(int, version_parts)\n",
    "\n",
    "        new_challenger_version = f\"v{major}_{minor + 1}\"\n",
    "        print(f\"New challenger: {new_challenger_version}\")\n",
    "        data[\"challenger\"] = {\n",
    "            \"model_version\": new_challenger_version,\n",
    "            \"deployed_at\": None,\n",
    "        }\n",
    "        blob.upload_from_string(json.dumps(data, indent=2))\n",
    "        return (\n",
    "            data[\"champion\"][\"model_version\"],\n",
    "            \"challenger-service\",\n",
    "            new_challenger_version,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "champion: v3_0\n",
      "challenger: v3_1\n",
      "Model accuracies: {'v3_1': 0.22826086956521724, 'v3_0': 0.5378091872791518}\n",
      "New challenger: v3_2\n"
     ]
    }
   ],
   "source": [
    "data, blob = load_model_versions()\n",
    "champion = data[\"champion\"][\"model_version\"]\n",
    "challenger = data[\"challenger\"][\"model_version\"]\n",
    "\n",
    "print(f\"champion: {champion}\\nchallenger: {challenger}\")\n",
    "\n",
    "# Step 2: Evaluate accuracy\n",
    "winner = evaluate_models(champion, challenger)\n",
    "\n",
    "# Step 3: Decide next model versions and services\n",
    "model_to_update, service_to_update, new_model_version = update_model_versions(\n",
    "    blob, data, winner, challenger\n",
    ")\n",
    "# print(model_to_update, service_to_update, new_model_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "creature-vis-0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
